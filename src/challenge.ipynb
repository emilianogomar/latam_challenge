{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q1_memory import q1_memory\n",
    "import q1_memory\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset modules to reload changes\n",
    "importlib.reload(q1_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Path definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:/Users/emili/Documents/farmers-protest-tweets-2021-2-4.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the file has duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the json file into a pandas DataFrame to check for duplicated rows\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "df = df.astype(str)\n",
    "\n",
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "# Define file path for the source twitter file\n",
    "file_path = r'C:/Users/emili/Documents/farmers-protest-tweets-2021-2-4.json'\n",
    "\n",
    "# Read the json file into a pandas DataFrame\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "# Normalize the DataFrame\n",
    "normalized_user = json_normalize(df['user'])\n",
    "\n",
    "#Add json prefix to all json columns\n",
    "normalized_user.columns = [f'json_{col}' for col in normalized_user.columns]\n",
    "\n",
    "# Combine normalized DataFrame with original DataFrame\n",
    "df = pd.concat([df.drop(columns='user'), normalized_user], axis=1)\n",
    "df = df.drop(columns='mentionedUsers')\n",
    "\n",
    "df = df.astype(str)\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "df.duplicated().any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_memory.q1_memory1(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "# Normalize the DataFrame\n",
    "normalized_user = json_normalize(df['user'])\n",
    "\n",
    "#Add json prefix to all json columns\n",
    "normalized_user.columns = [f'json_{col}' for col in normalized_user.columns]\n",
    "\n",
    "# Combine normalized DataFrame with original DataFrame\n",
    "df = pd.concat([df.drop(columns='user'), normalized_user], axis=1)\n",
    "\n",
    "# Drop all columns except Username and date\n",
    "columnas_a_mantener = ['date', 'json_username']\n",
    "\n",
    "# Eliminar todas las columnas excepto las dos especificadas\n",
    "df = df.drop(columns=[col for col in df.columns if col not in columnas_a_mantener])\n",
    "df['date'] = df['date'].dt.date\n",
    "df['json_username'] = df['json_username'].astype(str)\n",
    "\n",
    "df.info()\n",
    "\n",
    "top_fechas = df['date'].value_counts().head(10)\n",
    "\n",
    "top_fechas.head(10)\n",
    "\n",
    "usuarios_top_fechas = {}\n",
    "for fecha in top_fechas.index:\n",
    "    usuarios_top_fechas[fecha] = df[df['date'] == fecha]['json_username'].value_counts().idxmax()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Top 10 de fechas con más registros:\")\n",
    "print(top_fechas)\n",
    "print(\"\\nUsuario con más registros para cada fecha en el top 10:\")\n",
    "#for fecha, usuario in usuarios_top_fechas.items():\n",
    "#    print(f\"Fecha: {fecha}, Usuario: {usuario}\")\n",
    "\n",
    "#usuarios_top_fechas\n",
    "\n",
    "#lista_de_tuplas = list(df.to_records(index=False))\n",
    "\n",
    "# Mostrar la lista de tuplas resultante\n",
    "#lista_de_tuplas\n",
    "\n",
    "lista_de_tuplas = [(fecha, valor) for fecha, valor in usuarios_top_fechas.items()]\n",
    "\n",
    "lista_de_tuplas\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
